---
title: "Preliminary Paper"
format: docx
---
```{r, include=FALSE}
library(tidyverse)
library(ggplot2)
library(MASS)
library(dplyr)
library(ggrepel)
lda_data = readxl::read_excel("C:\\Users\\verde\\OneDrive\\Desktop\\Prelim\\Prelim\\data.xlsx")
```
### Introduction 
Treated as a social construct, self-identification along ethnic lines can be viewed through the lens of Social Identity Theory which argues that human categories are prototypes of integrated attributes (Hogg, 2016). In a nutshell, Social Identity Theory is defined as an individual's knowledge that they belong to a social group and they know the emotional and social significance of the group, i.e. they know what it means to "be" a member of a group. This self identification forms an individual's identity which is then mediated with the use of language particularly between two or more interlocutors (Ochs, 1993). This is all done by the interlocutors communicating by shared conventions that signify their identity and generate social meaning. One of the many forms of communicating conventions is through the production of specific sounds (Eckert & Labov, 2017) and stylistic choices in speech (Eckert & Podesva, 2011).

In the paper *Phonological Correlates of Ethnic Identity: Evidence of Divergence?* by Matthew J. Gordon, we find evidence of vowel production differences between four ethnic groups, White American, Mexican American, African American and biracial Americans. These differences are found along ethnic lines with regards to the Northern City Shift (NCS). African American and Mexican American speakers did not follow the general trend of /æ/ raising the same way that White Americans did. There were also fewer instances of "innovative" forms of production, i.e. White Americans led the change in vowel shifts while African and Mexican Americans tended to be more conservative in their speech. 
In Cananda, there has been evidence suggesting that Chinese Canadians had a vowel pattern that shifted differently when compared to White Canadians (Hoffman & Walker, 2010), while in a separate vain, Asian Americans in San Francisco largely followed the Low Back Merger as part of general Californian trend (Hall-Lew, 2009) though perhaps not to the same degree as White Californians (Cardoso et al, 2016).

This previous research suggests to me that vowel differences will be present along ethnic lines in California. California is experiencing a shift known as the Low-Back Merger (LBM) which involves the merge of the /ɔ/ and /ɑ/ vowels (Doernberger & Cerny, 2008), the raising of /æ/, the fronting of /u/ and the lowering of /I/ and /ɛ/ (Sheydaei, 2024). This paper, by conducting a Linear Discriminat Analysis of ""White" vowels and the "East Asian" vowels from university students in California, will provide preliminary evidence of production differences in line with Gordon (2000), Cardoso et al. (2016), and Sheydaei (2024). A Signal Detection Theory analysis will also be conducted to check the reliability of the results of the LDA. 

### Participants
The data for this study comes from 22 undergraduate students at the University of California, Davis. 12 self identified as East Asian (i.e. ethnically descendant of Japanese, Chinese, and Philippine peoples) and the remaining 10 self identified as White (i.e. ethnically descendant of European peoples). They were between the ages of 18 and 20. Each participant were recruited through the UC Davis SONA system.

### Data Collection
The procedure the participants followed was a straightforward one. After reading over information related to the study and signing a waiver allowing me to record them, they entered into a recording studio. After testing the sensitivity of the microphone I presented them with a Google Slides presentation containing the words I asked them to read. They were told that they would see a word on the screen and have 2 to 3 seconds to read the word before I switched to the next. They were told that not every word was a "real" word and to try their best.

Each word was typed in bright orange and presented against a white background. From my position outside of the recording booth, I clicked from slide to slide, word to word about every two seconds and made notes of words that the participant had difficulty with pronouncing. In a couple of instances, I asked participants to repeat a word after they had read through the entire list twice. For example, many participants would pronounce the word "head" in the same way the word "heed" is pronounced. Some words were unfamiliar to the participants even though they were real words. A couple were unsure about the pronunciation of the word "gin" and would produce the "g" with the voiced velar /g/ instead of the affricate /dz/. In total, each participant would repeat every word in the list twice. The list of words included HvD, BvD, BvT, pool/pull merger, pen/pin mergers, and two diphthongs the /oi/ before /l/ found in soil and the /ai/ found in sigh. The HvD words were to find neutral uses of the 10 English vowels (including /r/).

After the participants had completed their time in the recording booth, they were asked to answer a short questionnaire to gather specific information on their demographics. These included: what is your gender identity, what is your ethnic background, what area of California did you grow up in? These questions in an open-ended format because I wanted them to think about how they identified and I felt that yes or no questions were inadequate. I recognize my role in influencing the answers however as they could only answer the questions I asked them narrowing the ways in which they could identify. I asked these questions after they completed their time in the recording booth because I wanted them to read the provided stimuli as naturally as possible.

I recorded the participants using Praat and sampled at 44100 hertz. Each participant recording was done in a single wav file unless I had to re record an individual's production. In that case, I created a separate wav file that contained only the repeated word or words. I then used the cut and paste feature in Praat to paste the repeated word into the original wav file. After the recording had finished, I took the wav file recordings and hand annotated them to align the spectrographs with the written words. Following this, I used DARLA (Dartmouth Linguistic Automation) to properly align the segments of the words to their respective slices in the spectrographs.

Once I was satisfied with the alignments, it was time to turn to vowel extraction and analysis. Using the FastTrack plugin for Praat (Barreda, 2021) I extracted the vowels from each individual wav file using the aligned text grids and kept them stored as wav files for each production of a vowel and diphthong. Once completed, I used the TrackFolder command under the FastTrack plugin in Praat to run the LPC analysis to find the frequencies of the first three formants. I then normalized everyone's formants following log-mean normalization (Barreda et Nearey, 2018). 

### Data Analysis
This short paper will review the Linear Discriminant Analysis (LDA) of the "White" vowels and the "East Asian" vowels. Following that, a Signal Detection Theory (SDT) Analysis is conducted for each vowel. This steps are done for three reasons. First, if a model is able to correctly discriminate between the ethnicities using vowel formant data, its suggests that there exist differences in production. Second, If the sensitivity of the model (d') is 1.5 or higher for each vowel, the model does a pretty good job of distinguishing between the two ethnicities. Third, if the c value is at or near zero for each vowel, then any confusion found by the model is likely due to phonetic overlap.  The lda model (lda_model) is lda_model <- lda(vowel_ethnicity ~ f11-f15+f21-f25+f31-f35).

In plain English, I expect the model to predict the relative location of each vowel for each ethnicity within the vowel space. I will make these predictions given the start and end of the first, second, and third formants of each vowel. 

### LDA Predictions
```{r, include=FALSE}
lda_data=lda_data[lda_data$vowel!="i",]
```
```{r, include=FALSE}
lda_model <- lda(vowel_ethnicity ~ f11 + f21 + f31 + f15 + f25 + f35, 
                 data = lda_data)
predictions <- predict(lda_model)
confusion_matrix <- table(lda_data$vowel_ethnicity, predictions$class)
```
```{r, include=FALSE}
df_actual <- lda_data %>%
  group_by(vowel_ethnicity) %>%
  summarise(
    f1_avg = mean(rowMeans(across(c(f11, f15)), na.rm = TRUE)),
    f2_avg = mean(rowMeans(across(c(f21, f25)), na.rm = TRUE)),
    type = "Actual"
  )

# Compute predicted vowel-ethnicity averages
df_predicted <- lda_data %>%
  group_by(predicted_ethnicity, vowel) %>%  # Need vowel for clarity in grouping
  summarise(
    f1_avg = mean(rowMeans(across(c(f11, f15)), na.rm = TRUE)),
    f2_avg = mean(rowMeans(across(c(f21, f25)), na.rm = TRUE)),
    type = "Predicted"
  ) 

# Combine both sets into one dataset
df_plot01 <- bind_rows(df_actual, df_predicted)
```
```{r, include=FALSE}
df_plot_clean <- df_plot01 %>%
  filter(!is.na(vowel), !is.na(predicted_ethnicity))
```
```{r F1-1, echo=FALSE, fig.width=10, fig.height=7, warning=FALSE, fig.cap= "LDA Prediction of Vowels by Ethnicity"}
ggplot(df_plot_clean, aes(x = f2_avg, y = f1_avg, color = vowel, shape = predicted_ethnicity)) +
  geom_point(size = 4, alpha = 0.8) +  
  geom_text_repel(aes(label = vowel), size = 5, fontface = "bold") +  
  scale_y_reverse() +  
  scale_x_reverse() +  
  theme_classic() +
  labs(
    title = "",
    x = "F2 (Hz)",
    y = "F1 (Hz)",
    color = "Vowel",
    shape = "Predicted Ethnicity"
  ) +
  theme(
    legend.position = "bottom",
    axis.title = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12)
  )
```
The plot above shows the location of each vowel for the two ethnicities based on what the model predicted. Before I report the results of the SDT analysis I will highlight a three generalizations that I note from the plot. First, between White speakers and East Asian speakers, the front vowels (front of ɝ) are predicted to be different from each other mainly in terms of height. The most dramatic difference appears to be /eI/ and /I/ while /ɛ/ is less dramatic but still noticeable.

Second, the central vowels (between ɝ and ɔɪ) are not predicted to be different from each other. The model probably finds these vowels to be confusable. While it was generally clear that the East Asian speakers raised the front vowels more than the White speakers, I cannot find a generalizable pattern for the middle vowels. 

Third, the back vowels (especially /u/) are predicted to be dramatically different.The most striking prediciton is the difference in the fronting of /u/. /u/ fronting, a relatively common feature in North American English (Havenhill, 2004)(Kataoka, 2010), appears to be much more pronounced in white speakers than in East Asian speakers. The fronting of /ʊ/ in the White population is very surprising. In contrast to the front vowels, the back vowels are predicted to shift more in the White population than the East Asian population. 

With specific regards to the LBM, the fronting of /u/ fits the predicted pattern while the lowering of /ɪ/ and /ɛ/ don't. I suspect that the White population is leading the shift more so than the East Asian population. 

### SDT Analysis
The SDT Analysis is to test the reliability of the model. I am also following the suggestions of my committee chair in running a bootstrap analysis of the data. I will re-sample the participants 1000 times from the two populations and run a new lda analysis. This analysis will sever the link between formant data and ethnicity, allowing me to compare a null hypothesis, that there are no differences between the populations, to the data predicted by the original lda analysis. By doing this, I will juxtapose the re-sampled data that does not link phonetics and ethnicity to the real data that has the two linked. This will be done in addition to the d prime and bias information. 
```{r, include=FALSE}
winner_class = predict(lda_model)$class
winner_tmp = unlist (strsplit (as.character(winner_class), "_"))
winner_vowel = winner_tmp[seq(1,length(winner_tmp),2)]
winner_eth = winner_tmp[seq(2,length(winner_tmp),2)]

mean(lda_data$ethnicity == winner_eth)
tapply (lda_data$ethnicity == winner_eth, lda_data$vowel, mean)
```
```{r, include=FALSE}
hit = (lda_data$ethnicity == "EA") & (winner_eth == "EA")
fa = (lda_data$ethnicity == "W") & (winner_eth == "EA")

hit_vowel = tapply (hit, lda_data[,c("vowel","ethnicity")], mean)[,1]
fa_vowel = tapply (fa, lda_data[,c("vowel","ethnicity")], mean)[,2]

dprime = bmmb::ptoz(hit_vowel) - bmmb::ptoz(fa_vowel)
bias = (bmmb::ptoz(hit_vowel) + bmmb::ptoz(fa_vowel))/2
```

```{r, include=FALSE}
dat_list = split (lda_data, lda_data$participant)
ea = c(1,6,11:16,18:21)
w = (1:22)[-ea]

n = 1000 

dprimes = matrix (0, n,13)
biases = matrix (0, n,13)
```
```{r, include=FALSE}
for (i in 1:n){
  if (i %% 100 == 0) {
    print (i)
  }
  
  ea_tmp = sample (ea, 12, replace = TRUE)
  w_tmp = sample (w, 10, replace = TRUE)
  
  dat_tmp = do.call (rbind, dat_list[c(ea_tmp, w_tmp)])

  lda_model = MASS::lda (vowel_ethnicity ~ f11 + f15 + f21 + f25 + f31 + f35, data = dat_tmp)
  
  winner_class = predict(lda_model)$class
  winner_tmp = unlist (strsplit (as.character(winner_class), "_"))
  winner_vowel = winner_tmp[seq(1,length(winner_tmp),2)]
  winner_eth = winner_tmp[seq(2,length(winner_tmp),2)]

  #mean(dat_tmp$ethnicity == winner_eth)
  #tapply (dat_tmp$ethnicity == winner_eth, dat_tmp$vowel, mean)
  
  hit = (dat_tmp$ethnicity == "EA") & (winner_eth == "EA")
  fa = (dat_tmp$ethnicity == "W") & (winner_eth == "EA")
  
  hit_vowel = tapply (hit, dat_tmp[,c("vowel","ethnicity")], mean)[,1]
  fa_vowel = tapply (fa, dat_tmp[,c("vowel","ethnicity")], mean)[,2]
  
  dprimes[i,] = bmmb::ptoz(hit_vowel) - bmmb::ptoz(fa_vowel)
  biases[i,] = (bmmb::ptoz(hit_vowel) + bmmb::ptoz(fa_vowel))/2
  
}
```
```{r, echo=FALSE}
dprimes_null = matrix (0, n,13)
biases_null = matrix (0, n,13)
```
```{r, include=FALSE}
for (i in 1:n){
  if (i %% 100 == 0) {
  }
  
  tmp_ = sample (1:22, 11, replace = FALSE)
  tmp = sample (tmp_, 11, replace = TRUE)
  dat_tmp1 = do.call (rbind, dat_list[tmp])
  tmp = sample ((1:22)[-tmp_], 11, replace = TRUE)
  dat_tmp2 = do.call (rbind, dat_list[tmp])
  
  dat_tmp1$ethnicity = "EA"
  dat_tmp2$ethnicity = "W"
  
  dat_tmp = rbind (dat_tmp1, dat_tmp2)
  
  lda_model = MASS::lda (vowel_ethnicity ~ f11 + f15 + f21 + f25 + f31 + f35, data = dat_tmp)
  
  winner_class = predict(lda_model)$class
  winner_tmp = unlist (strsplit (as.character(winner_class), "_"))
  winner_vowel = winner_tmp[seq(1,length(winner_tmp),2)]
  winner_eth = winner_tmp[seq(2,length(winner_tmp),2)]
  
  hit = (dat_tmp$ethnicity == "EA") & (winner_eth == "EA")
  fa = (dat_tmp$ethnicity == "W") & (winner_eth == "EA")

  hit_vowel = tapply (hit, dat_tmp[,c("vowel","ethnicity")], mean)[,1]
  fa_vowel = tapply (fa, dat_tmp[,c("vowel","ethnicity")], mean)[,2]
  
  dprimes_null[i,] = bmmb::ptoz(hit_vowel) - bmmb::ptoz(fa_vowel)
  biases_null[i,] = (bmmb::ptoz(hit_vowel) + bmmb::ptoz(fa_vowel))/2
}
```
```{r,echo=FALSE, fig.cap="Sensitivity (Green) and Biase Values (Red) Compared to Null Predictions to the Right"}
par (mfcol = c(2,2), mar = c(4,4,1,1))
boxplot (dprimes, col = 3)
abline (h=0)
boxplot (biases, col = 2)
abline (h=0)

boxplot (dprimes_null, col = 3)
abline (h=0)
boxplot (biases_null, col = 2)
abline (h=0)
```
The plot above shows broad generalizations between the true data and the re-sampled data.I have to reject the null hypothesis. Compared to the null estimates (the right plots) there is clearly a difference between the true data that has phonetics and ethnicity linked and the data that has them unlinked. The D Prime values in the true data are all positive, with a few negative outliers, suggesting that the machine is decently sensitive to the phonetic differences between the ethniciites. Meanwhile, the null hypthoses has the mean values right at zero suggesting that if there were no phonetic differences between the two groups, there would be complete overlap between the two.  

The Bias information follows the re-sampled data a little more closely. The means of the c values are largely positive suggesting a more conservative model. There are even several outliers that are strongly positive. This means that the model avoids many false alarms but also misses genuine hits causing it to err on the side of caution. Interestingly, the null hypothesis also has mean values that are mostly positive values. If there were no phonetic differences between the two groups, then the machine would still err on the side of caution. 
```{r,echo=FALSE, fig.cap="Sensitivity and Bias"}
par (mfcol = c(2,1), mar = c(2,4,.5,1))
bmmb::brmplot (brms::posterior_summary(dprimes), labels = sort(unique(lda_data$vowel)))
bmmb::brmplot (brms::posterior_summary(dprimes,probs = c(.1,.9)), 
               add = TRUE, lwd=5, col=3, labels = "")
points (1:13, dprime, pch=4, col=3, cex=2)
mtext ("Sensitivity", side=2, line=2.5)
bmmb::brmplot (brms::posterior_summary(biases), labels = sort(unique(lda_data$vowel)))
bmmb::brmplot (brms::posterior_summary(biases,probs = c(.1,.9)), 
               add = TRUE, lwd=5, col=2, labels = "")
points (1:13, bias, pch=4, col=2, cex=2)
mtext ("Bias", side=2, line = 2.5)
```
The plots above are better visualizations of the of the sensitivity and bias values from the true data. The mean value for each vowel is positive with the lowest value coming from /u/. This is interesting considering the /u/ was one of the values most predicted to be different. I interpret this to mean that one of the two ethnicities has lower internal variation, i.e. there could be more overlap of their /u/ vowels. The other ethnicity would necessarily have higher internal variation and that variation is what the model used to differentiate between the two. The other vowels mentioned earlier in the paper, those most closely associated with LBM, this reasoning remains. Within group variation appears to be high while cross group variation is low. 

With the exception of /ɑ/ and /u/ most values are between 1 and 3 suggesting that while the machine is fully capable of predicting differences due to phonetic production, there is likely still overlap between the two groups. This is not surprising. Every participant is of the same generation and grew up in California.  
  
The bias information is also positive. This suggests that the machine is erring on the side of caution when assigning its predictions. It has few false alarms but it may be missing a few hits at the same time. I think this could be because of the amount of general overlap between the two groups. As stated, the sensitivity values are largely between 1 and 3, i.e. the two groups have a good amount of vowel overlap. By erring on the side of caution, the model lowers its risk of mistaking that overlap. The vowel /æ/ interestingly is right at zero. The model has no bias against the vowel. 

Overall, the model has done a decently good job at discriminating and predicting vowels along the ethnic lines. By comparing the null data to the true data, one can reasonable argue that the two groups do have different phonetic productions. These differences in all likely do overlap, possibly because of their shared regional dialect, and by making more conservative predictions, the model is able to reconcile that overlap. 

### Discussion 
Based on the predictions made the model, it appears that the White population and the East Asian population had different vowel spaces. These spaces aren't different in terms shape, that is impossible, but in terms of scale. The White population appears to front their back vowels much more than the East Asian population while the later produces higher front vowels. Importantly, these differences are phonetic in nature and not phonemic, i.e. the /u/ of one population will be identified as an /u/ even though the formant values of it will be different. 

In terms of the LBM, it appears that the White population follows that general trend. Their /ɛ/ and /ɪ/ were lower than that of the East Asian population suggesting that they are lowering those vowels with respect with the other group. Their /u/ was also predicted to be much more fronted, again following the trend of /u/ fronting. 

This fits the previous work done showing that ethnic minorities produce their vowels in phonetically different ways. In the Northern cities, the African American and Mexican American populations followed the general patterns of the Northern City Shift while White Americans began to differ from it (Gordon, 2000). In Toronto, Chinese Canadians went against the features of the Canadian Vowel Shift (Hoffman & Walker, 2010). From my perspective, without having a non-California with which to compare, I cannot make a claim as to whether or not (or to what degree) the East Asian population follows the LBM trend. I can make a claim they appear to follow it less so than the White population.

After reviewing the SDT analysis, I am fairly common that the five vowels mentioned are produced differently between the two groups even though some overlap exists. Both populations are the same age group and both live in a small college town in the Sacramento Valley. If there were no overlap between the two, the differences would instead be phonemic and not phonetic. Ultimately, in order to be more confident in the results, I will need more participants to gather more data. 

### Next Steps and Conclusion
The next steps in this project are to 1: gather more speakers to train a more confident model and 2: take the predictions of that model and present them to listeners. If listeners are able to confidently discriminate between the two groups given a produced vowel, I can be fairly confident that these productions can be markers of ethnic identity. 

While I did not discuss the meaning of ethnicity in this paper, I cannot end it without noting the its fluid nature. Ethnicity is not a concrete object, it is a construction and as such no two people will define it the same. In fact, no two people who identify as the same ethnicity will perform that ethnicity in the exact same way. This paper proposes that dispite this fluidity, individuals will perform their ethnicity in similar ways. 

### References 
Austen, M. (2020). Production and perception of the Pin-Pen merger. Journal of Linguistic Geography, 8(2), 115--126. doi:10.1017/jlg.2020.9

Barreda, S. Nearey, T. (2018). A regression approach to vowel normalization for missing and unbalanced data.Journal of the Acoustical Society of America, 144, 500-520.

Barreda, Santiago. "Fast Track: fast (nearly) automatic formant-tracking using Praat" Linguistics Vanguard, vol. 7, no. 1, 2021, pp. 20200051.

Cardoso, A., Hall–Lew, L., Kementchedjhieva, Y. & Purse, R. 2016. ‘Between California and the Pacific Northwest: The front lax vowels in San Francisco English.’ American Speech, 101(1), 33–54.

Eckert, P., & Podesva, R. J. (2011). Sociophonetics and sexuality: Toward a symbiosis of sociolinguistics and laboratory phonology. American Speech, 86(1), 6-13.

Eckert, P. and Labov, W. (2017), Phonetics, phonology and social meaning. J Sociolinguistics, 21: 467-496. https://doi.org/10.1111/josl.12244.

Foulkes, P. Docherty, G. The social life of phonetics and phonology, Journal of Phonetics, Volume 34, Issue 4, 2006, Pages 409-438, ISSN 0095-4470, https://doi.org/10.1016/j.wocn.2005.08.002.

GeeksforGeeks. (n.d.). Linear Discriminant Analysis in R Programming. GeeksforGeeks. https://www.geeksforgeeks.org/linear-discriminant-analysis-in-r-programming/

Gordon, Matthew. Phonological Correlates of Ethnic Identity: Evidence of Divergence?. American Speech, Volume 75, Number2, Summer 2000, pp.115-136.

Hall-Lew, L. (2009). Ethnicity and phonetic variation in a San Francisco neighborhood. Stanford University.

Havenhill, J. (2024). Articulatory and acoustic dynamics of fronted back vowels in American English. The Journal of the Acoustical Society of America, 155(4), 2285–2301. https://doi.org/10.1121/10.0025461 

Hoffman, M. F. & Walker, J. A. 2010. ‘Ethnolects and the city: Ethnic orientation and linguistic variation in Toronto English.’ Language Variation and Change, 22(1), 37–67.10.1017/S0954394509990238

Hogg, M. A. (2016). Social identity theory (pp. 3-17). Springer International Publishing.

Johnson, K. (2006). Resonance in an exemplar-based lexicon: The emergence of social identity and phonology. Journal of Phonetics, 34(4), 485--499. https://doi.org/10.1016/j.wocn.2005.08.004

Linear discriminant analysis. Nat Rev Methods Primers 4, 71 (2024). https://doi.org/10.1038/s43586-024-00357-9

Ochs, E. (1993). Constructing Social Identity: A Language Socialization Perspective. Research on Language and Social Interaction, 26(3), 287--306. https://doi.org/10.1207/s15327973rlsi2603_3

Podesva, R. J., D'Onofrio, A., Van Hofwegen, J., & Kim, S. K. (2015). Country ideology and the California Vowel Shift. Language Variation and Change, 27(2), 157--186. doi:10.1017/S095439451500006X

Podesva, Robert J; D'Onofrio, Annette; Van Hofwegen, Janneke; Kim, Seung Kyung.  Language Variation and Change; Cambridge Vol. \` 27, Iss. 2, (Jul 2015): 157-186. DOI:10.1017/S095439451500006X

Thomas, E.R. (2013). Sociophonetics. In The Handbook of Language Variation and Change (eds J.K. Chambers and N. Schilling). https://doi.org/10.1002/9781118335598.ch5

Sheydaei, I. (2024). The Low-Back-Merger Shift: Evidence from MENA Americans in the Upper Midwest and southern California: MENA Americans and the Low‑Back‑Merger Shift. English Today, 40(1), 22–31. doi:10.1017/S0266078423000299

Sumner, M., Kim, S. K., King, E., & McGowan, K. B. (2014). The socially weighted encoding of spoken words: A dual-route approach to speech perception. Frontiers in Psychology, 4, 1015.

Villarreal, D. (2018). The Construction of Social Meaning: A Matched-Guise Investigation of the California Vowel Shift. Journal of English Linguistics, 46(1), 52-78. https://doi.org/10.1177/0075424217753520
